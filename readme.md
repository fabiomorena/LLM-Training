# Fine-Tuning & RAG-System auf einem MacBook Air

Dieses Projekt dokumentiert den gesamten Prozess des Fine-Tunings, der Optimierung und der Erweiterung eines modernen Sprachmodells (`microsoft/phi-3-mini-instruct`) zu einem RAG-System auf einem Apple MacBook Air. Es dient als praxisnahes Beispiel f√ºr die Herausforderungen und L√∂sungen bei der Arbeit mit gro√üen Sprachmodellen auf Consumer-Hardware.

---
## ‚ú® Features

* **End-to-End-Workflow:** Von der Idee √ºber das Training bis zur fertigen, interaktiven Anwendung.
* **Modernes KI-Modell:** Fine-Tuning des leistungsstarken `phi-3-mini-instruct` (3.8 Mrd. Parameter).
* **Effizientes Training:** Einsatz von **PEFT/LoRA** zur Minimierung des Speicher- und Rechenbedarfs.
* **Inferenz-Optimierung:** Konvertierung des trainierten Modells in das hochperformante **GGUF-Format** mit 8-Bit-Quantisierung.
* **Retrieval-Augmented Generation (RAG):** Das Modell kann Fragen basierend auf Inhalten aus benutzerdefinierten PDF-Dokumenten beantworten.
* **Konversationelles Ged√§chtnis:** Die RAG-Anwendung nutzt "Query Transformation", um Folgefragen im Gespr√§chskontext zu verstehen.
* **Interaktive Web-App:** Eine mit **Gradio** erstellte Benutzeroberfl√§che f√ºr die einfache Interaktion mit dem finalen Modell.

---
## üõ†Ô∏è Verwendete Technologien

* **Python 3.11**
* **PyTorch** (mit MPS-Beschleunigung f√ºr Apple Silicon)
* **Hugging Face Libraries:**
    * `transformers`
    * `peft` (f√ºr LoRA)
    * `datasets`
    * `accelerate`
* **RAG & Inferenz:**
    * `llama-cpp-python` (f√ºr GGUF-Modelle)
    * `chromadb` (Vektor-Datenbank)
    * `sentence-transformers` (f√ºr Embeddings)
    * `pypdf` (zum Lesen von PDFs)
* **UI & Entwicklung:**
    * `gradio` (f√ºr die Web-App)
    * Git & GitHub
    * PyCharm auf macOS

---
## üöÄ Setup & Installation

1.  **Repository klonen:**
    ```bash
    git clone [https://github.com/fabiomorena/LLM-Training.git](https://github.com/fabiomorena/LLM-Training.git)
    cd LLM-Training
    ```

2.  **Virtuelle Umgebung erstellen und aktivieren:**
    ```bash
    python3 -m venv venv
    source venv/bin/activate
    ```

3.  **Abh√§ngigkeiten installieren:**
    ```bash
    pip install torch transformers datasets peft accelerate gradio llama-cpp-python sentencepiece chromadb pypdf
    ```

---
## üèÉ‚Äç‚ôÄÔ∏è Anwendung

Das Herzst√ºck des Projekts ist die finale RAG-Anwendung.

### ### Die RAG-App starten

1.  **Dokumente bereitstellen:** Erstelle einen Ordner namens `rag_dokumente` und lege die PDF-Dateien hinein, mit denen du chatten m√∂chtest.
2.  **Wissensdatenbank erstellen:** F√ºhre das Skript aus, um die Dokumente zu verarbeiten und in der Vektor-Datenbank zu speichern.
    ```bash
    python create_database.py
    ```
3.  **App starten:** Starte die Gradio-Anwendung.
    ```bash
    python app.py
    ```
4.  √ñffne anschlie√üend die lokale URL (z.B. `http://127.0.0.1:7860`) in deinem Webbrowser und stelle Fragen zu deinen Dokumenten.

---
## üßó‚Äç‚ôÇÔ∏è Die Projekt-Reise: Herausforderungen & L√∂sungen

Dieses Projekt war eine intensive Lernreise. Die gr√∂√üten H√ºrden und ihre L√∂sungen waren:
* **Abh√§ngigkeitskonflikte:** Moderne KI-Bibliotheken entwickeln sich schnell. Ein zentraler Teil des Projekts war das Debuggen von Inkompatibilit√§ten zwischen `transformers`, `peft` und dem `phi-3`-Modellcode. Die L√∂sung war die Installation eines "goldenen Trios" von zueinander passenden Bibliotheksversionen.
* **Hardware-Grenzen:** Das Training eines 3.8-Milliarden-Parameter-Modells sprengte die RAM-Grenzen des MacBook Air. Dies wurde durch clevere Software-Tricks wie **Gradient Checkpointing** und einen speichersparenden **Optimizer (`adafactor`)** umgangen.
* **Optimierungs-Toolchain:** Die Quantisierung mit `bitsandbytes` scheiterte an der Hardware-Inkompatibilit√§t. Der Wechsel zur `llama.cpp/GGUF`-Toolchain war die L√∂sung, um eine hochperformante, Mac-freundliche Version des Modells zu erstellen. Dieser Wechsel brachte eigene Herausforderungen mit sich (veraltete Skripte, fehlende Dateien), die schrittweise gel√∂st wurden.
* **Konversationelles Ged√§chtnis f√ºr RAG:** Das RAG-System konnte anfangs keine Folgefragen verstehen. Dies wurde durch die Implementierung einer **"Query Transformation"** gel√∂st, bei der das LLM die Nutzeranfrage basierend auf dem Gespr√§chsverlauf selbst pr√§zisiert.

---
## üìÑ Lizenz

Dieses Projekt steht unter der MIT-Lizenz..

---
## üë§ Autor

* **Fabio Morena**
* GitHub: [github.com/fabiomorena](https://github.com/fabiomorena)